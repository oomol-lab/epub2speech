#!/usr/bin/env python3
import sys
import os
import traceback
import random
import unittest
from pathlib import Path

sys.path.insert(0, os.path.join(os.path.dirname(os.path.dirname(__file__))))

from epub2speech.epub_picker import EpubPicker

TEST_BOOKS = [
    {
        "filename": "The little prince.epub",
        "sample_chapters": [
            {
                "nav_title": "Chapter I",
                "href": "7358.xhtml",
                "expected_head": "Chapter I Once when I was six years old I saw a magnificent picture in a book, called True Stories from Nature, about the primeval forest. It was a pi",
                "expected_tail": "el. I would talk to him about bridge, and golf, and politics, and neckties. And the grown-up would be greatly pleased to have met such a sensible man."
            },
            {
                "nav_title": "Chapter II",
                "href": "7521.xhtml",
                "expected_head": "Chapter II So I lived my life alone, without anyone that I could really talk to, until I had an accident with my plane in the Desert of Sahara, six ye",
                "expected_tail": "\" He bent his head over the drawing: \"Not so small that-- Look! He has gone to sleep...\" And that is how I made the acquaintance of the little prince."
            },
            {
                "nav_title": "Chapter III",
                "href": "7664.xhtml",
                "expected_head": "Chapter III It took me a long time to learn where he came from. The little prince, who asked me so many questions, never seemed to hear the ones I ask",
                "expected_tail": "esn't matter. Where I live, everything is so small!\" And, with perhaps a hint of sadness, he added: \"Straight ahead of him, nobody can go very far...\""
            },
            {
                "nav_title": "Chapter IV",
                "href": "7747.xhtml",
                "expected_head": "Chapter IV I had thus learned a second fact of great importance: this was that the planet the little prince came from was scarcely any larger than a h",
                "expected_tail": " like himself. But I, alas, do not know how to see sheep through the walls of boxes. Perhaps I am a little like the grown-ups. I have had to grow old."
            },
            {
                "nav_title": "Chapter X",
                "href": "8525.xhtml",
                "expected_head": "Chapter X He found himself in the neighbourhood of the asteroids 325, 326, 327, 328, 329, and 330. He began, therefore, by visiting them, in order to ",
                "expected_tail": ", hastily. He had a magnificent air of authority. \"The grown-ups are very strange,\" the little prince said to himself, as he continued on his journey."
            }
        ]
    },
    {
        "filename": "æ˜æœé‚£äº›äº‹å„¿.epub",
        "sample_chapters": [
            {
                "nav_title": "åºè¨€",
                "href": "chap_1.xhtml",
                "expected_head": "åºè¨€ æœ¬ä¹¦ç”±çˆ±ä¸Šé˜…è¯»çš„ç½‘å‹æœé›†æ•´ç†ï¼Œæ›´å¤šç²¾å½©ä¹¦ç±è¯·è®¿é—®https://www.isyd.net å£°æ˜ï¼šæœ¬ä¹¦æ¥è‡ªäº’è”ç½‘ï¼Œä»…ä¾›å‚è€ƒã€æŸ¥é˜…èµ„æ–™ï¼Œç‰ˆæƒå½’ä½œè€…æ‰€æœ‰ï¼ï¼ æ•¬å‘Šï¼šè¯·åœ¨ä¸‹è½½åçš„24å°æ—¶å†…åˆ é™¤",
                "expected_tail": "æˆ‘æƒ³å†™çš„ï¼Œæ˜¯ä¸€éƒ¨å¯ä»¥åœ¨è½»æ¾ä¸­äº†è§£å†å²çš„ä¹¦ï¼Œä¸€éƒ¨å¥½çœ‹çš„å†å²ã€‚ ä»…æ­¤è€Œå·²ï¼ å¥½äº†ï¼Œå°±æ­¤å¼€å§‹å§ã€‚"
            },
            {
                "nav_title": "ç¬¬ä¸€ç«  ç«¥å¹´",
                "href": "chap_2.xhtml",
                "expected_head": "ç¬¬ä¸€ç«  ç«¥å¹´ æˆ‘ä»¬ä»ä¸€ä»½æ¡£æ¡ˆå¼€å§‹ã€‚ å§“åï¼šæœ±å…ƒç’‹ åˆ«åï¼ˆå¤–å·ï¼‰ï¼šæœ±é‡å…«ã€æœ±å›½ç‘ æ€§åˆ«ï¼šç”· æ°‘æ—ï¼šæ±‰ è¡€å‹ï¼šï¼Ÿ å­¦å†ï¼šæ— æ–‡å‡­ï¼Œç§€æ‰ä¸¾äººè¿›å£«ç»Ÿç»Ÿçš„ä¸æ˜¯",
                "expected_tail": "è¿™ä¸€å¹´ï¼Œä»–åä¸ƒå²ã€‚ å¾ˆå¿«ä¸€åœºç¾éš¾å°±è¦é™ä¸´åˆ°ä»–çš„èº«ä¸Šï¼Œä½†åŒæ—¶ï¼Œä¸€ä¸ªä¼Ÿå¤§çš„äº‹ä¸šä¹Ÿåœ¨ç­‰å¾…ç€ä»–ã€‚åªæœ‰åƒä¼ è¯´ä¸­çš„å‡¤å‡°ä¸€æ ·ï¼Œå†ç»è‹¦éš¾ï¼ŒæŠ•å…¥ç«ä¸­"
            },
            {
                "nav_title": "åè®°\næœ¬æ¥æ²¡æƒ³å†™ï¼Œä½†è¿˜æ˜¯å†™ä¸€ä¸ªå§ï¼Œæ¯•ç«Ÿé‚£ä¹ˆå¤šå­—éƒ½å†™äº†ã€‚",
                "href": "chap_159.xhtml",
                "expected_head": "åè®° æœ¬æ¥æ²¡æƒ³å†™ï¼Œä½†è¿˜æ˜¯å†™ä¸€ä¸ªå§ï¼Œæ¯•ç«Ÿé‚£ä¹ˆå¤šå­—éƒ½å†™äº†ã€‚",
                "expected_tail": "è®ºè‘—åˆé›†ã€‹ï¼Œå•†é¸¿é€µï¼ŒåŒ—äº¬å¤§å­¦å‡ºç‰ˆç¤¾1988å¹´ç‰ˆï¼› ã€ŠäºŒåäº”å²æ–°ç¼–ã€‹ï¼Œä¸Šæµ·å¤ç±å‡ºç‰ˆç¤¾2004å¹´ç‰ˆï¼› ã€Šæ¸…å²æ–°è€ƒã€‹ï¼Œç‹é”ºç¿°ï¼Œè¾½å®å¤§å­¦å‡ºç‰ˆç¤¾1990å¹´ç‰ˆï¼› ã€Šæ˜æ¸…å²æ–°æã€‹ï¼ŒéŸ¦åº†è¿œï¼Œä¸­å›½ç¤¾ä¼šç§‘å­¦å‡ºç‰ˆç¤¾1995å¹´ç‰ˆï¼› ã€Šæ˜äº¡æ¸…å…´å…­åå¹´ã€‹ï¼Œé˜å´‡å¹´ï¼Œä¸­åä¹¦å±€2006å¹´ç‰ˆï¼› ã€Šè¢å´‡ç„•ä¼ ã€‹ï¼Œé˜å´‡å¹´ï¼Œä¸­åä¹¦å±€2005å¹´ç‰ˆï¼› ã€Šæ¨å¤§æ´ªå…ˆç”Ÿæ–‡é›†ã€‹ï¼Œï¼ˆæ˜ï¼‰æ¨æ¶Ÿï¼› ã€Šä¸‰å£ç¬”è®°ã€‹ï¼Œï¼ˆæ˜ï¼‰ææ¸…ï¼› ã€Šæ¨æ–‡å¼±å…ˆç”Ÿé›†ã€‹ï¼Œï¼ˆæ˜ï¼‰æ¨å—£æ˜Œã€‚"
            }
        ]
    },
    {
        "filename": "Ming dynasty.epub",
        "sample_chapters": [
            {
                "nav_title": "Start",
                "href": "index.html",
                "expected_head": "The Ming dynasty, officially the Great Ming, was an imperial dynasty of China that ruled from 1368 to 1644, following the collapse of the Mongol-led Y",
                "expected_tail": "t it was defeated shortly afterwards by the Manchu-led Eight Banner armies of the Qing dynasty, with the help of the defecting Ming general Wu Sangui."
            }
        ]
    },
    {
        "filename": "Ming dynasty no ncx ref.epub",
        "sample_chapters": [
            {
                "nav_title": "Index",
                "href": "index.html",
                "expected_head": "The Ming dynasty, officially the Great Ming, was an imperial dynasty of China that ruled from 1368 to 1644, following the collapse of the Mongol-led Y",
                "expected_tail": "t it was defeated shortly afterwards by the Manchu-led Eight Banner armies of the Qing dynasty, with the help of the defecting Ming general Wu Sangui."
            }
        ]
    }
]


def compare_text_head_tail(extracted_text, expected_head, expected_tail, max_chars=200):
    if not extracted_text:
        return False, False, "", ""

    # è·å–å¤´éƒ¨æ–‡æœ¬ï¼ˆæœ€å¤š max_chars å­—ç¬¦ï¼‰
    head_actual = extracted_text[:max_chars] if len(extracted_text) > max_chars else extracted_text
    # è·å–å°¾éƒ¨æ–‡æœ¬ï¼ˆæœ€å¤š max_chars å­—ç¬¦ï¼‰
    tail_actual = extracted_text[-max_chars:] if len(extracted_text) > max_chars else extracted_text

    # æ¯”è¾ƒå¤´éƒ¨ï¼ˆå¿½ç•¥å¤§å°å†™å’Œç©ºç™½å·®å¼‚ï¼‰
    head_match = expected_head.lower() in head_actual.lower()

    # æ¯”è¾ƒå°¾éƒ¨ï¼ˆå¿½ç•¥å¤§å°å†™å’Œç©ºç™½å·®å¼‚ï¼‰
    tail_match = expected_tail.lower() in tail_actual.lower()

    return head_match, tail_match, head_actual, tail_actual


class TestTextExtractor(unittest.TestCase):
    """Test cases for text extraction functionality"""

    def test_extractor_functionality(self):
        """Test text extractor functionality"""
        print("ğŸ§ª Starting text extractor functionality test...\n")

        all_passed = True

        for book_data in TEST_BOOKS:
            filename = book_data["filename"]
            sample_chapters = book_data["sample_chapters"]

            print(f"ğŸ“š Testing book: {filename}")

            with self.subTest(book=filename):
                try:
                    # åˆ›å»º picker å®ä¾‹
                    epub_path = Path(__file__).parent / "assets" / filename
                    picker = EpubPicker(epub_path)

                    # æµ‹è¯•æ¯ä¸ªæŠ½æ ·ç« èŠ‚
                    for i, chapter_data in enumerate(sample_chapters):
                        nav_title = chapter_data["nav_title"]
                        href = chapter_data["href"]
                        expected_head = chapter_data["expected_head"]
                        expected_tail = chapter_data["expected_tail"]

                        print(f"   ğŸ“„ Testing chapter {i+1}: {nav_title}")

                        # æå–æ–‡æœ¬
                        extracted_text = picker.extract_text(href)

                        if not extracted_text:
                            print(f"      âš ï¸  No text extracted from {href}")
                            continue

                        # æ¯”è¾ƒå¤´éƒ¨å’Œå°¾éƒ¨
                        head_match, tail_match, head_actual, tail_actual = compare_text_head_tail(
                            extracted_text, expected_head, expected_tail
                        )

                        # éªŒè¯ç»“æœ
                        self.assertTrue(head_match,
                                      f"Head mismatch for {nav_title}\nExpected: ...{expected_head[-50:]}...\nActual:   ...{head_actual[-50:]}...")
                        self.assertTrue(tail_match,
                                      f"Tail mismatch for {nav_title}\nExpected: ...{expected_tail[:50]}...\nActual:   ...{tail_actual[:50:]}...")

                        # æ˜¾ç¤ºæˆåŠŸä¿¡æ¯
                        head_chars = min(200, len(head_actual))
                        print(f"      âœ… Head matches (first ~{head_chars} chars)")
                        tail_chars = min(200, len(tail_actual))
                        print(f"      âœ… Tail matches (last ~{tail_chars} chars)")
                        print(f"      ğŸ“Š Extracted {len(extracted_text)} characters total")

                    print(f"   âœ… {filename} text extraction tests completed\n")

                except Exception as e:
                    print(f"   âŒ {filename} test failed: {e}")
                    all_passed = False
                    traceback.print_exc()

        self.assertTrue(all_passed, "Some text extraction tests failed!")
        print("ğŸ‰ All text extraction tests passed!")

    def generate_test_data(self):
        """Generate test data from EPUB files - utility method"""
        print("ğŸ”§ Generating test data from EPUB files...\n")

        # ä½¿ç”¨ç°æœ‰çš„ TEST_BOOKS æ¥è·å–æ–‡ä»¶ååˆ—è¡¨ï¼Œé¿å…é‡å¤ç»´æŠ¤
        test_books = [book["filename"] for book in TEST_BOOKS]
        generated_data = []

        for filename in test_books:
            print(f"ğŸ“Š Analyzing {filename}...")

            try:
                epub_path = Path(__file__).parent / "assets" / filename
                picker = EpubPicker(epub_path)
                nav_items = list(picker.get_nav_items())

                if not nav_items:
                    print(f"   âš ï¸  No navigation items found in {filename}")
                    continue

                print(f"   Found {len(nav_items)} chapters")

                # éšæœºé€‰æ‹© 2-3 ä¸ªç« èŠ‚è¿›è¡Œé‡‡æ ·ï¼ˆå¦‚æœç« èŠ‚è¶³å¤Ÿå¤šï¼‰
                sample_size = min(3, len(nav_items))
                if len(nav_items) > sample_size:
                    sample_items = random.sample(nav_items, sample_size)
                else:
                    sample_items = nav_items

                book_data = {
                    "filename": filename,
                    "sample_chapters": []
                }

                for nav_title, href in sample_items:
                    print(f"   ğŸ“„ Sampling: {nav_title}")

                    extracted_text = picker.extract_text(href)

                    if extracted_text:
                        # è·å–å¤´éƒ¨å’Œå°¾éƒ¨æ–‡æœ¬
                        head_text = extracted_text[:200] if len(extracted_text) > 200 else extracted_text
                        tail_text = extracted_text[-200:] if len(extracted_text) > 200 else extracted_text

                        chapter_data = {
                            "nav_title": nav_title,
                            "href": href,
                            "expected_head": head_text,
                            "expected_tail": tail_text
                        }
                        book_data["sample_chapters"].append(chapter_data)

                        char_count = len(extracted_text)
                        print(f"      âœ“ Extracted {char_count} characters")
                    else:
                        print("      âš ï¸  No text extracted")

                if book_data["sample_chapters"]:
                    generated_data.append(book_data)
                    chapter_count = len(book_data['sample_chapters'])
                    print(f"   âœ… Generated data for {chapter_count} chapters\n")
                else:
                    print(f"   âš ï¸  No valid chapters found for {filename}")
                    print()

            except Exception as e:
                print(f"   âŒ Error processing {filename}: {e}")
                print()
                traceback.print_exc()

        print("ğŸ“‹ Generated test data structure:")
        print("You can copy this to replace TEST_BOOKS in test_extractor.py")
        print("=" * 60)
        print("TEST_BOOKS = [")
        for book_data in generated_data:
            print("    {")
            print(f'        "filename": "{book_data["filename"]}",')
            print('        "sample_chapters": [')
            for chapter in book_data["sample_chapters"]:
                print("            {")
                print(f'                "nav_title": "{chapter["nav_title"]}",')
                print(f'                "href": "{chapter["href"]}",')
                # å¤„ç†æ–‡æœ¬ä¸­çš„å¼•å·å’Œç‰¹æ®Šå­—ç¬¦
                head_escaped = chapter["expected_head"].replace('"', '\\"').replace('\n', '\\n')
                tail_escaped = chapter["expected_tail"].replace('"', '\\"').replace('\n', '\\n')
                print(f'                "expected_head": "{head_escaped}",')
                print(f'                "expected_tail": "{tail_escaped}"')
                print("            },")
            print("        ]")
            print("    },")
        print("]")
        print("=" * 60)


if __name__ == "__main__":
    unittest.main(verbosity=2)